{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies nécessaires\n",
    "import dotenv # Pour lire nos variables environnements avec nos APIs\n",
    "\n",
    "# On importe quelques librairies de manipulation de données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# On importe les modules nécessaires de LangChain\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFaceHub, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "weekday = [\"Lundi\",\"Mardi\",\"Mercredi\",\"Jeudi\",\"Vendredi\",\"Samedi\",\"Dimanche\"]\n",
    "\n",
    "tod_date = datetime.date.today()\n",
    "week_day = weekday[datetime.date.today().weekday()]\n",
    "tod_hour = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeudi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On lit nos variables environnments avec nos clés APIs\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_new_tokens\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Quelle temps fera-t-il demain soir à Lyon  ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_last_brace(text):\n",
    "    # Index de la dernière accolade fermante\n",
    "    last_brace_index = -1\n",
    "\n",
    "    for i, char in enumerate(text):\n",
    "        if char == '}':\n",
    "            last_brace_index = i\n",
    "    json_str = text[:last_brace_index+1]\n",
    "    return json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def premier_json(chaine):\n",
    "    debut_json = chaine.find('{')  # Trouver le début du premier JSON\n",
    "    fin_json = chaine.find('}', debut_json) + 1  # Trouver la fin du premier JSON\n",
    "    json_str = chaine[debut_json:fin_json]  # Extraire le JSON\n",
    "    try:\n",
    "        premier_json = json.loads(json_str)  # Charger le JSON\n",
    "        return premier_json\n",
    "    except json.JSONDecodeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt fonctionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ville': 'Lyon', 'date': '2024/03/15', 'heure': '09'}\n"
     ]
    }
   ],
   "source": [
    "temp1 = \"\"\"[INST]\n",
    "        Tu dois extraire des informations de la phrase données.\n",
    "\n",
    "        N'invente pas, et extrait dans un JSON valide la VILLE et la DATE et l'HEURE. Si tu ne sait pas, mets 'None'.\n",
    "        l'HEURE doit etre une heure valide.\n",
    "        Aujourd'hui, nous sommes le {0} {1} à {2}h.\n",
    "\n",
    "        Le JSON doit avoir ce format:\n",
    "        (\n",
    "        \"ville\":\"ville\",\n",
    "        \"date\":\"%Y/%m/%d\",\n",
    "        \"heure\":\"HH\"\n",
    "        )\n",
    "\n",
    "        ----- \n",
    "\"\"\".format(week_day,tod_date.strftime('%Y/%m/%d'),tod_hour.strftime('%H'))\n",
    "temp2 = \"\"\"\n",
    "        Voici la requête :\n",
    "            {query}\n",
    "\n",
    "            [/INST]\n",
    "        JSON:\n",
    "\"\"\"\n",
    "\n",
    "templ = temp1 + temp2\n",
    "\n",
    "query = \"Quel méteo fera-t-il à Lyon demain à 9 heure ?\"\n",
    "\n",
    "# On instancie notre template de prompt où l'on indique que nos deux variables entrantes sont le contexte (documents) et la requête (question)\n",
    "promp_rag = PromptTemplate(input_variables=[\"query\"], template=templ)\n",
    "chain = LLMChain(prompt=promp_rag, llm=llm,verbose=False)\n",
    "response = chain.invoke({\"query\": query})\n",
    "answer = response[\"text\"].split(\"JSON:\")[1]\n",
    "json_fin = remove_after_last_brace(answer)\n",
    "\n",
    "# On le place dans une variable pour indiquer que ce sera le prompt de notre retriever\n",
    "print(json_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double prompt (Fonctionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2024/08/22', 'heure': 'None', 'ville': 'Nice'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Mon anniversaire est le 22 aout.Je vais le faire dans ma famille à Nice. Est-ce qu'il fera beau ?\"\n",
    "\n",
    "temp1 = f'''[INST] Tu dois extraire la Date et l'Heure approximative indiquée dans la query.\n",
    "        Estime la date au besoin.\n",
    "        Si tu n'es pas sûr de l'heure ou de la date, mets 'None'.\n",
    "        Aujourd'hui, nous sommes le {week_day} {tod_date.strftime('%Y/%m/%d')} à {tod_hour.strftime('%H')} h.\n",
    "        Le matin commence à 9 h, l'après-midi commence à 15 h et le soir à 19 h. \n",
    "        Le JSON doit avoir ce format:\n",
    "        \"date\":\"%Y/%m/%d\",\n",
    "        \"heure\":\"HH\"\n",
    "\n",
    "        ----- \n",
    "        '''\n",
    "temp2 = \"\"\"\n",
    "        Voici la query :\n",
    "            {query}\n",
    "\n",
    "            [/INST]\n",
    "        Reponse_:\n",
    "        \"\"\"\n",
    "templ_1 = temp1 + temp2\n",
    "\n",
    "# On instancie notre template de prompt où l'on indique que nos deux variables entrantes sont le contexte (documents) et la requête (question)\n",
    "promp_rag = PromptTemplate(input_variables=[\"query\"], template=templ_1)\n",
    "chain = LLMChain(prompt=promp_rag, llm=llm,verbose=False)\n",
    "response = chain.invoke({\"query\": query})\n",
    "answer = response[\"text\"].split(\"Reponse_:\")[1]\n",
    "json_fin = remove_after_last_brace(answer)\n",
    "\n",
    "template_2 = \"\"\"[INST]\n",
    "                Voici un Json :\n",
    "                {json}\n",
    "                Extrait l'information de la VILLE de la QUERY et ajoute le à ce JSON. (\"ville\":). Si tu ne sait pas, met \"None\".\n",
    "                Renvois le JSON avec ce format : {{\"date\":, \"heure\":, \"ville\":}}.\n",
    "                Pas besoin d'explication.\n",
    "                ----- \n",
    "                Voici la query :\n",
    "                {query}\n",
    "\n",
    "                [/INST]\n",
    "                Reponse_:\n",
    "                \"\"\"\n",
    "\n",
    "# On le place dans une variable pour indiquer que ce sera le prompt de notre retriever\n",
    "promp_rag_2 = PromptTemplate(input_variables=[\"query\"], template=template_2)\n",
    "chain_2 = LLMChain(prompt=promp_rag_2, llm=llm,verbose=False)\n",
    "response_2 = chain_2.invoke({\"query\": query,\"json\":json_fin})\n",
    "answer_2 = response_2[\"text\"].split(\"Reponse_:\")[1]\n",
    "json_fin_2 = premier_json(answer_2)\n",
    "\n",
    "print(json_fin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_liste = [\"Quel méteo fera-t-il à Lyon demain à 9 heure ?\",\n",
    "               \"Quel temps la semaine prochaine à Paris ?\",\n",
    "               \"Il fait beau lundi prochain à vaise ?\",\n",
    "               \"Le temps sera bon ce week end ?\",\n",
    "               \"Il fait bon demain après-midi ?\",\n",
    "               \"Donne moi le temps du 16 mars 2024 ?\",\n",
    "               \"Quel temps fait-il le vendredi 15 Mars ?\",\n",
    "               \"Mon anniversaire est le 22 aout.Je vais le faire dans ma famille à Nice. Est-ce qu'il fera beau ?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "Quel méteo fera-t-il à Lyon demain à 9 heure ?\n",
      "{'date': '2024/03/15', 'heure': '09'}\n",
      "{'date': '2024/03/15', 'heure': '09', 'ville': 'Lyon'}\n",
      "Query 1:\n",
      "Quel temps la semaine prochaine à Paris ?\n",
      "{'date': '2024/03/21', 'heure': 'None'}\n",
      "{'date': '2024/03/21', 'heure': 'None', 'ville': 'Paris'}\n",
      "Query 2:\n",
      "Il fait beau lundi prochain à vaise ?\n",
      "{'date': '2024/03/18', 'heure': 'None'}\n",
      "{'date': '2024/03/18', 'heure': 'None', 'ville': 'Vaise'}\n",
      "Query 3:\n",
      "Le temps sera bon ce week end ?\n",
      "{'date': '2024/03/16', 'heure': 'None'}\n",
      "{'date': '2024/03/16', 'heure': 'None', 'ville': 'None'}\n",
      "Query 4:\n",
      "Il fait bon demain après-midi ?\n",
      "{'date': '2024/03/15', 'heure': '15'}\n",
      "{'date': '2024/03/15', 'heure': '15', 'ville': 'None'}\n",
      "Query 5:\n",
      "Donne moi le temps du 16 mars 2024 ?\n",
      "{'date': '2024/03/16', 'heure': 'None'}\n",
      "{'date': '2024/03/16', 'heure': 'None', 'ville': 'None'}\n",
      "Query 6:\n",
      "Quel temps fait-il le vendredi 15 Mars ?\n",
      "{'date': '2024/03/15', 'heure': 'None'}\n",
      "{'date': '2024/03/15', 'heure': 'None', 'ville': 'None'}\n"
     ]
    }
   ],
   "source": [
    "# On boucle sur la query\n",
    "for id, item in enumerate(query_liste):\n",
    "    response = chain.invoke({\"query\": item})\n",
    "    answer = response[\"text\"].split(\"Reponse_:\")[1]\n",
    "    json_fin = remove_after_last_brace(answer)\n",
    "    template_2 = \"\"\"[INST]\n",
    "                Voici un Json :\n",
    "                {json}\n",
    "                Extrait l'information de la VILLE de la QUERY et ajoute le à ce JSON. (\"ville\":). Si tu ne sait pas, met \"None\".\n",
    "                Renvois le JSON avec ce format : {{\"date\":, \"heure\":, \"ville\":}}.\n",
    "                Pas besoin d'explication.\n",
    "                ----- \n",
    "                Voici la query :\n",
    "                {query}\n",
    "\n",
    "                [/INST]\n",
    "                Reponse_:\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # On le place dans une variable pour indiquer que ce sera le prompt de notre retriever\n",
    "    promp_rag_2 = PromptTemplate(input_variables=[\"query\"], template=template_2)\n",
    "    chain_2 = LLMChain(prompt=promp_rag_2, llm=llm,verbose=False)\n",
    "    response_2 = chain_2.invoke({\"query\": item,\"json\":json_fin})\n",
    "    answer_2 = response_2[\"text\"].split(\"Reponse_:\")[1]\n",
    "    json_fin_2 = premier_json(answer_2)\n",
    "    print(f\"Query {id}:\")\n",
    "    print(item)\n",
    "    print(json_fin)\n",
    "    #print(answer_2)\n",
    "    print(json_fin_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json(json_object,date,hour):\n",
    "    tod_h = hour.strftime('%H')\n",
    "    new_json = json_object\n",
    "    if list(json_object.values()) == ['None','None','None']:\n",
    "        return \"Need to re-ask\"\n",
    "    if json_object[\"ville\"] == 'None':\n",
    "        new_json[\"ville\"] = \"Lyon\"\n",
    "    \n",
    "    day_plus_five = date + datetime.timedelta(days=5)\n",
    "    if json_object[\"heure\"] < tod_h : \n",
    "        json_object[\"heure\"] = tod_h + 1\n",
    "    if (json_object[\"date\"] > day_plus_five.strftime('%Y/%m/%d')) & (json_object[\"date\"] != 'None'):        \n",
    "        new_json[\"date\"] = day_plus_five.strftime('%Y/%m/%d')\n",
    "    \n",
    "    return new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_test = {'ville': 'Paris', 'date': '2024/03/15', 'heure': '19'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ville': 'Lyon', 'date': '2024/03/18', 'heure': '18'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = clean_json(json_fin,tod_date,tod_hour)\n",
    "new_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
