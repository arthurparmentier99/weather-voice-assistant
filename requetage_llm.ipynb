{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies nécessaires\n",
    "import dotenv # Pour lire nos variables environnements avec nos APIs\n",
    "\n",
    "# On importe quelques librairies de manipulation de données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# On importe les modules nécessaires de LangChain\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFaceHub, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "tod_date = datetime.date.today()\n",
    "tod_hour = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On lit nos variables environnments avec nos clés APIs\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_new_tokens\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST]\n",
    "        Tu dois extraire des informations de la phrase données. \n",
    "        N'invente pas, et extrais dans un JSON le LIEU et la DATE.\n",
    "        Aujourd'hui, nous sommes le 13/03/2024.\n",
    "        Renvoit un JSON de la forme avec le \"lieu\" et la \"date\", ainsi que les informations additionnelles dans une liste.\n",
    "        Uniquement le JSON.\n",
    "        ----- \n",
    "\n",
    "        Voici la requête :\n",
    "            {query}\n",
    "\n",
    "            [/INST]\n",
    "        JSON:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_last_brace(text):\n",
    "    # Index de la dernière accolade fermante\n",
    "    last_brace_index = -1\n",
    "\n",
    "    for i, char in enumerate(text):\n",
    "        if char == '}':\n",
    "            last_brace_index = i\n",
    "    json_str = text[:last_brace_index+1]\n",
    "    return json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Donne le temps à Saint-brieuc jeudi prochain\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ville': 'Lyon', 'date': '2024/03/14', 'heure': 'None'}\n"
     ]
    }
   ],
   "source": [
    "template =\"\"\"[INST]\n",
    "        Tu dois extraire des informations de la phrase données.\n",
    "\n",
    "        N'invente pas, et extrais dans un JSON valide la VILLE et la DATE et l'HEURE. Si tu ne sait pas, met 'None'.\n",
    "        l'HEURE doit etre une heure valide.\n",
    "        Aujourd'hui, nous sommes le 13/03/2024 à 12h.\n",
    "\n",
    "        Le JSON doit avoir ce format:\n",
    "        (\n",
    "        \"ville\":\"ville\",\n",
    "        \"date\":\"YYYY/MM/DD\",\n",
    "        \"heure\":\"HH\"\n",
    "        )\n",
    "\n",
    "        ----- \n",
    "\n",
    "        Voici la requête :\n",
    "            {query}\n",
    "\n",
    "            [/INST]\n",
    "        JSON:\n",
    "\"\"\"\n",
    "\n",
    "query = \"Quelle temps fait-t-il demain à Lyon?\"\n",
    "\n",
    "# On instancie notre template de prompt où l'on indique que nos deux variables entrantes sont le contexte (documents) et la requête (question)\n",
    "promp_rag = PromptTemplate(input_variables=[\"query\"], template=template)\n",
    "chain = LLMChain(prompt=promp_rag, llm=llm,verbose=False)\n",
    "response = chain.invoke({\"query\": query})\n",
    "answer = response[\"text\"].split(\"JSON:\")[1]\n",
    "json_fin = remove_after_last_brace(answer)\n",
    "\n",
    "# On le place dans une variable pour indiquer que ce sera le prompt de notre retriever\n",
    "print(json_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        {\n",
      "        \"ville\": \"Paris\",\n",
      "        \"date\": \"2024/03/13\",\n",
      "        \"heure\": \"24\"\n",
      "        }\n",
      "\n",
      "        Explication:\n",
      "        Dans la question donnée, il n'y a pas de mention d'un changement de date ou d'heure, donc on suppose que l'événement a lieu le même jour que la date mentionnée dans l'introduction, qui est le 13/03/2024. Pour l'heure, on suppose que la nuit est considérée comme étant à 24h, même si cela n'est pas une heure valide dans un format de temps standard.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json(json_object,date,hour):\n",
    "    tod_date = date.strftime('%Y/%m/%d')\n",
    "    tod_h = hour.strftime('%H')\n",
    "    new_json = json_object\n",
    "    if list(json_fin.values()) == ['None','None','None']:\n",
    "        return \"Need to re-ask\"\n",
    "    if json_object[\"ville\"] == 'None':\n",
    "        new_json[\"ville\"] = \"Lyon\"\n",
    "    if json_object[\"date\"] == 'None':\n",
    "        new_json[\"date\"] = tod_date\n",
    "    if json_object[\"heure\"] == 'None':\n",
    "        new_json[\"heure\"] = tod_h\n",
    "    \n",
    "    day_plus_five = date + datetime.timedelta(days=5)\n",
    "    if json_object[\"heure\"] < tod_h : \n",
    "        json_object[\"heure\"] = tod_h\n",
    "    if json_object[\"date\"] > day_plus_five.strftime('%Y/%m/%d'):        \n",
    "        new_json[\"date\"] = day_plus_five.strftime('%Y/%m/%d')\n",
    "    \n",
    "    return new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 3, 13)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tod_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ville': 'lyon', 'date': '2024/03/18', 'heure': '17'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = clean_json(json_fin,tod_date,tod_hour)\n",
    "(new_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
